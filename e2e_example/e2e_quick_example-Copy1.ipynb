{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7807189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e388ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "from tensorflow.data.experimental import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "159d1abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-samples-data/ai-platform/mnist_tfrecord/test.tfrecord\n",
      "gs://cloud-samples-data/ai-platform/mnist_tfrecord/train.tfrecord\n",
      "gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/\n",
      "gs://cloud-samples-data/ai-platform/mnist_tfrecord/pretrained/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-samples-data/ai-platform/mnist_tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce5b49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-samples-data/ai-platform/mnist/t10k-images-idx3-ubyte\n",
      "gs://cloud-samples-data/ai-platform/mnist/t10k-images-idx3-ubyte.gz\n",
      "gs://cloud-samples-data/ai-platform/mnist/t10k-labels-idx1-ubyte\n",
      "gs://cloud-samples-data/ai-platform/mnist/t10k-labels-idx1-ubyte.gz\n",
      "gs://cloud-samples-data/ai-platform/mnist/train-images-idx3-ubyte\n",
      "gs://cloud-samples-data/ai-platform/mnist/train-images-idx3-ubyte.gz\n",
      "gs://cloud-samples-data/ai-platform/mnist/train-labels-idx1-ubyte\n",
      "gs://cloud-samples-data/ai-platform/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-samples-data/ai-platform/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1efcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/e2e_example\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73528d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8982518",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GS_MNIST']=\"gs://cloud-samples-data/ai-platform/mnist/\" \n",
    "os.environ['GS_MNIST_TFRECORD'] = 'gs://cloud-samples-data/ai-platform/mnist_tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf15df38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.33 MiB    gs://cloud-samples-data/ai-platform/mnist_tfrecord\n"
     ]
    }
   ],
   "source": [
    "!gsutil du -sh $GS_MNIST_TFRECORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be63cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbb52d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/Dockerfile...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/setup.py...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/training/__init__.py...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/training/load_saved_model.py...\n",
      "- [4 files][  3.0 KiB/  3.0 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/training/mnist_to_tfrecord.py...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/custom_job/training/task.py...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/pretrained/saved_model.pb...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/pretrained/variables/variables.data-00000-of-00001...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/pretrained/variables/variables.index...\n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/test.tfrecord...     \n",
      "Copying gs://cloud-samples-data/ai-platform/mnist_tfrecord/train.tfrecord...    \n",
      "- [11 files][ 56.3 MiB/ 56.3 MiB]                                               \n",
      "Operation completed over 11 objects/56.3 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r $GS_MNIST_TFRECORD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56df626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2020 Google LLC\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     https://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "import argparse\n",
      "\n",
      "import tensorflow as tf\n",
      "\n",
      "\n",
      "def make_and_compile_model(learning_rate):\n",
      "    model = tf.keras.Sequential([\n",
      "        tf.keras.layers.Input(shape=(28, 28, 1)),\n",
      "        tf.keras.layers.Conv2D(filters=2, kernel_size=3),\n",
      "        tf.keras.layers.Flatten(),\n",
      "        tf.keras.layers.Dense(units=10, activation='softmax')\n",
      "    ])\n",
      "\n",
      "    model.compile(\n",
      "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
      "        loss=tf.keras.losses.CategoricalCrossentropy())\n",
      "\n",
      "    return model\n",
      "\n",
      "\n",
      "def make_tf_dataset(train_data_gcs_uri):\n",
      "    raw_ds = tf.data.TFRecordDataset(train_data_gcs_uri)\n",
      "\n",
      "    # See the SerializeToString call in mnist_to_tfrecord.py.\n",
      "    def parse(serialized):\n",
      "        feature_description = {\n",
      "            'label': tf.io.FixedLenFeature([], tf.int64),\n",
      "            'image_raw': tf.io.FixedLenFeature([], tf.string)\n",
      "        }\n",
      "\n",
      "        return tf.io.parse_single_example(serialized, feature_description)\n",
      "\n",
      "    # See the tobytes call in mnist_to_tfrecord.py.\n",
      "    def decode(parsed):\n",
      "        flattened_image = tf.io.decode_raw(parsed['image_raw'], out_type=tf.uint8)\n",
      "        image = tf.reshape(flattened_image, (28, 28, 1))\n",
      "\n",
      "        return {'image': image, 'label': parsed['label']}\n",
      "\n",
      "    def transform(decoded):\n",
      "        image = decoded['image']\n",
      "        feature = tf.cast(image, tf.float32) / 255.0\n",
      "\n",
      "        label = decoded['label']\n",
      "        target = tf.one_hot(label, depth=10)\n",
      "\n",
      "        return (feature, target)\n",
      "\n",
      "\n",
      "    parsed_ds = raw_ds.map(parse)\n",
      "    decoded_ds = parsed_ds.map(decode)\n",
      "    ds = decoded_ds.map(transform)\n",
      "\n",
      "    return ds\n",
      "\n",
      "\n",
      "def main(args):\n",
      "    dataset = make_tf_dataset(args.train_data_gcs_uri)\n",
      "    model = make_and_compile_model(args.learning_rate)\n",
      "\n",
      "    model.fit(\n",
      "        x=dataset.shuffle(1024).batch(args.batch_size),\n",
      "        epochs=args.epochs\n",
      "    )\n",
      "\n",
      "    # Define a serving signature to accept image raw bytes.\n",
      "    # Note that the same code is also used in make_tf_dataset.\n",
      "    @tf.function\n",
      "    def serve(image_raw, key):\n",
      "        flattened_image = tf.io.decode_raw(image_raw, out_type=tf.uint8)\n",
      "        image = tf.reshape(flattened_image, (1, 28, 28, 1))\n",
      "        feature = tf.cast(image, tf.float32) / 255.0\n",
      "\n",
      "        output = model(feature)\n",
      "\n",
      "        return {'scores': output, 'key': key}\n",
      "\n",
      "    signature = serve.get_concrete_function(image_raw=tf.TensorSpec([None,], dtype=tf.string), key=tf.TensorSpec([None,], dtype=tf.string))\n",
      "\n",
      "    model.save(\n",
      "        filepath=args.model_dir,\n",
      "        save_format='tf',\n",
      "        # This would be added under the `serving_default` signature key.\n",
      "        signatures=signature\n",
      "    )\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument('--train_data_gcs_uri', default='gs://cloud-samples-data/ai-platform/mnist_tfrecord/train.tfrecord', type=str)\n",
      "    parser.add_argument('--model_dir', default='/tmp/mnist', type=str)\n",
      "\n",
      "    parser.add_argument('--learning_rate', default=0.1, type=float)\n",
      "    parser.add_argument('--batch_size', default=32, type=int)\n",
      "    parser.add_argument('--epochs', default=2, type=int)\n",
      "\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    main(args)\n"
     ]
    }
   ],
   "source": [
    "!cat data/mnist_tfrecord/custom_job/training/task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12db262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = tf.data.TFRecordDataset('data/mnist_tfrecord/train.tfrecord', \n",
    "                               num_parallel_reads=AUTOTUNE)\n",
    "# next(iter(data))\n",
    "def parse(example):\n",
    "    feature_descriptions = {\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string)\n",
    "    }    \n",
    "    return tf.io.parse_single_example(example, feature_descriptions)\n",
    "def decode()\n",
    "\n",
    "# next(iter(data.map(parse)))\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
